{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2147190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "from datetime import datetime as dt\n",
    "from db.db_operations import execute_db_operations\n",
    "\n",
    "from generators.full_generators import (\n",
    "    create_company_data\n",
    ")\n",
    "\n",
    "company_name = \"Lego\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff1d74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data for company: Lego...\n",
      "Using existing context report for Lego.\n",
      "Context data for Lego generated: {'company_name': 'Lego', 'count_employee': 550, 'count_department': 25, 'count_customer': 55, 'count_product': 180, 'count_procurement': 140, 'count_service': 140, 'count_account': 60, 'count_vendor': 75, 'estimated_product': 105000000, 'estimated_service': 40000000, 'estimated_overhead': 442000000, 'estimated_revenue': 649000000}\n",
      "Generating dimensions for company: Lego.\n",
      "This usually takes 2-5 mins.\n",
      "\n",
      "=== Attempt 1 ===\n",
      "✔ Roles and Names generated.\n",
      "✔ Procurement data generated.\n",
      "✔ Services data generated.\n",
      "✔ Products data generated.\n",
      "✔ Accounts data generated.\n",
      "✔ Customers data generated.\n",
      "✔ Departments data generated.\n",
      "✔ Vendors data generated.\n",
      "✔ Payroll data generated.\n",
      "✔ All table lengths validated.\n",
      "✔ All CSVs saved to: data/outputdata\n",
      "\n",
      " * Semantic mapping started * :\n",
      "Time estimate: 3-5 minutes\n",
      "✔ Procurement mapping done!\n",
      "✔ Service mapping done!\n",
      "✔ Product mapping done!\n",
      "✔ All mapping data generated.\n",
      "✔ All mapping CSVs saved to: data/outputdata/mapping\n",
      "✔ All erp-data generated.\n",
      "✔ All ERP CSVs saved to: data/outputdata/fact\n",
      "✔ All ERP data and mapping generated for company: Lego\n"
     ]
    }
   ],
   "source": [
    "data = create_company_data(company_name=company_name, save_to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94b69ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserting 25 rows into dim_department using to_sql...\n",
      "[INFO] Inserting 55 rows into dim_customer using to_sql...\n",
      "[INFO] Inserting 180 rows into dim_product using to_sql...\n",
      "[INFO] Inserting 60 rows into dim_account using to_sql...\n",
      "[INFO] Inserting 140 rows into dim_procurement using to_sql...\n",
      "[INFO] Inserting 140 rows into dim_service using to_sql...\n",
      "[INFO] Inserting 14 rows into dim_payline using to_sql...\n",
      "[INFO] Inserting 75 rows into dim_vendor using to_sql...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserting 550 rows into dim_employee using to_sql...\n",
      "[INFO] Inserting 554400 rows into fact_payroll using to_sql...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n",
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n",
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n",
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n",
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n",
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserting 49920 rows into fact_general_ledger using to_sql...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n",
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n",
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n",
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n",
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n",
      "c:\\Users\\jsteensgaard\\OneDrive - KPMG\\Documents\\Synthetic_Data_Generation\\db\\db_operations.py:61: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserting 33355 rows into fact_budget using to_sql...\n"
     ]
    }
   ],
   "source": [
    "now = dt.now()\n",
    "version_tag = (\n",
    "    company_name.lower()\n",
    "    + \"_date_\" + now.strftime(\"%m%d\")\n",
    "    + \"_time_\" + now.strftime(\"%H%M%S\")\n",
    ")\n",
    "execute_db_operations(version_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d80a4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_revenue_items_llm(company_name: str, count: int = 100, model: str = \"gpt-4.1\", temp: float = 0.8):\n",
    "    \"\"\"\n",
    "    Generate revenue items (e.g. product/service revenue categories) for a company.\n",
    "    Each item will be mapped to a Revenue-type account in the Chart of Accounts.\n",
    "    \"\"\"\n",
    "\n",
    "    client = prompt_utils.get_openai_client()\n",
    "    over_request_count = int(np.floor(int(count) * 1.4))\n",
    "\n",
    "    header = \"name;revenue_segment;proportionality\"\n",
    "    constraints = prompt_utils.get_standard_constraints(header, over_request_count)\n",
    "    ctxb = prompt_utils._ctx_block(company_name)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a financial analyst and ERP expert.\n",
    "    Generate a realistic ranked list of {over_request_count} **revenue items** for {company_name}, Denmark-only.\n",
    "\n",
    "    Fields:\n",
    "    - name = revenue line item (e.g., \"Running Shoes Sales\", \"Consulting Services\", \"Subscription Fees\")\n",
    "    - revenue_segment = category (e.g., Product Revenue, Service Revenue, Licensing, Subscription, Consulting)\n",
    "    - proportionality = share of total company revenue\n",
    "\n",
    "    Rules:\n",
    "    - Cover both major product revenues and service/other revenues where applicable.\n",
    "    - Use realistic naming aligned with company operations/industry.\n",
    "    - Ensure categories can map logically to Chart of Accounts entries of type 'Revenue'.\n",
    "    - Rank by proportionality (desc).\n",
    "    - Avoid vague terms like \"Miscellaneous Revenue\".\n",
    "\n",
    "    For context, here is a short version of the latest year-end report for {company_name}:\n",
    "    {ctxb}\n",
    "\n",
    "    {constraints}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful financial analyst and ERP mapping assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=temp,\n",
    "    )\n",
    "\n",
    "    df_revenue = prompt_utils.parse_and_truncate_csv(response.choices[0].message.content, count)\n",
    "\n",
    "    # Add unique IDs for the revenue items\n",
    "    df_revenue.insert(0, \"revenue_id\", range(50, len(df_revenue) + 50))\n",
    "\n",
    "    # Convert proportionalities to percentages (scaled to 1.0)\n",
    "    df_revenue = utils.convert_column_to_percentage(df_revenue, \"proportionality\", scale=1.0)\n",
    "\n",
    "    return df_revenue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf12a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cogs_items_llm(company_name: str, count: int = 100, model: str = \"gpt-4.1\", temp: float = 0.8):\n",
    "    \"\"\"\n",
    "    Generate COGS (Cost of Goods Sold) items for a company.\n",
    "    Each item should map to Product Expense or Service Expense accounts in the COA.\n",
    "    \"\"\"\n",
    "\n",
    "    client = prompt_utils.get_openai_client()\n",
    "    over_request_count = int(np.floor(int(count) * 1.4))\n",
    "\n",
    "    header = \"name;cogs_segment;proportionality\"\n",
    "    constraints = prompt_utils.get_standard_constraints(header, over_request_count)\n",
    "    ctxb = prompt_utils._ctx_block(company_name)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a financial analyst and ERP expert.\n",
    "    Generate a realistic ranked list of {over_request_count} **COGS (Cost of Goods Sold) items** \n",
    "    for {company_name}, Denmark-only.\n",
    "\n",
    "    Fields:\n",
    "    - name = specific COGS line item (e.g., \"Raw Materials\", \"Packaging\", \"Shipping Costs\", \"Outsourced Manufacturing\", \"Implementation Services\")\n",
    "    - cogs_segment = category (e.g., Product COGS, Service Delivery Costs, Logistics, Manufacturing Support)\n",
    "    - proportionality = share of total COGS\n",
    "\n",
    "    Rules:\n",
    "    - Ensure items logically map to Chart of Accounts entries of type \"Product Expense\" or \"Service Expense\".\n",
    "    - Cover both direct material/product-related COGS and service/operational delivery costs.\n",
    "    - Include raw materials, components, packaging, logistics, service subcontracting, hosting, etc.\n",
    "    - Rank by proportionality (desc).\n",
    "    - Avoid vague placeholders like \"Miscellaneous Costs\".\n",
    "\n",
    "    For context, here is a short version of the latest year-end report for {company_name}:\n",
    "    {ctxb}\n",
    "\n",
    "    {constraints}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful financial analyst and ERP mapping assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=temp,\n",
    "    )\n",
    "\n",
    "    df_cogs = prompt_utils.parse_and_truncate_csv(response.choices[0].message.content, count)\n",
    "\n",
    "    # Add unique IDs for the COGS items\n",
    "    df_cogs.insert(0, \"cogs_id\", range(200, len(df_cogs) + 200))\n",
    "\n",
    "    # Normalize proportionalities\n",
    "    df_cogs = utils.convert_column_to_percentage(df_cogs, \"proportionality\", scale=1.0)\n",
    "\n",
    "    return df_cogs\n",
    "\n",
    "def generate_ebit_items_llm(company_name: str, count: int = 100, model: str = \"gpt-5\", temp: float = 0.9):\n",
    "    \"\"\"\n",
    "    Generate realistic EBIT (Operating Income & Expense) items for a company.\n",
    "    These represent the main operating costs and incomes between Gross Profit and Operating Profit.\n",
    "    \"\"\"\n",
    "\n",
    "    client = prompt_utils.get_openai_client()\n",
    "    over_request_count = int(np.floor(int(count) * 1.4))\n",
    "\n",
    "    header = \"name;ebit_segment;proportionality\"\n",
    "    constraints = prompt_utils.get_standard_constraints(header, over_request_count)\n",
    "    ctxb = prompt_utils._ctx_block(company_name)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    {ctxb}\n",
    "\n",
    "    You are a financial analyst and ERP data modeler.\n",
    "    Generate a realistic ranked list of {over_request_count} **EBIT items (Operating Income & Expenses)** \n",
    "    for {company_name}, Denmark-only.\n",
    "\n",
    "    Fields:\n",
    "    - name = EBIT line item\n",
    "    - ebit_segment = category (e.g., Selling & Distribution, Administration, Production Overhead, Other Operating Income)\n",
    "    - proportionality = share of total EBIT impact (absolute value, 0–1 range)\n",
    "\n",
    "    Rules:\n",
    "    - Include both operating costs and operating income directly below gross profit.\n",
    "    - Exclude financing, tax, and extraordinary items.\n",
    "    - Reflect realistic operating structure for the given company and industry.\n",
    "    - Rank by proportionality (descending).\n",
    "    - Avoid placeholders such as \"Miscellaneous expenses\" or \"Other income\".\n",
    "\n",
    "    {constraints}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful ERP and finance assistant who outputs clean CSV tables for P&L modeling.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=temp,\n",
    "    )\n",
    "\n",
    "    df_ebit = prompt_utils.parse_and_truncate_csv(response.choices[0].message.content, count)\n",
    "\n",
    "    # Assign IDs\n",
    "    df_ebit.insert(0, \"ebit_id\", range(400, 400 + len(df_ebit)))\n",
    "\n",
    "    # Normalize proportionalities\n",
    "    df_ebit = utils.convert_column_to_percentage(df_ebit, \"proportionality\", scale=1.0)\n",
    "\n",
    "    return df_ebit\n",
    "\n",
    "\n",
    "def generate_inventory_items_llm(company_name: str, count: int = 100, model: str = \"gpt-5\", temp: float = 0.9):\n",
    "    \"\"\"\n",
    "    Generate realistic Inventory items for a company.\n",
    "    Each item should correspond to balance sheet Inventory accounts such as Raw Materials, WIP, or Finished Goods.\n",
    "    \"\"\"\n",
    "\n",
    "    client = prompt_utils.get_openai_client()\n",
    "    over_request_count = int(np.floor(int(count) * 1.4))\n",
    "\n",
    "    header = \"name;inventory_segment;proportionality\"\n",
    "    constraints = prompt_utils.get_standard_constraints(header, over_request_count)\n",
    "    ctxb = prompt_utils._ctx_block(company_name)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    {ctxb}\n",
    "\n",
    "    You are a financial analyst and ERP data modeler.\n",
    "    Generate a realistic ranked list of {over_request_count} **Inventory items** for {company_name}, Denmark-only.\n",
    "\n",
    "    Fields:\n",
    "    - name = specific inventory line item\n",
    "    - inventory_segment = category (e.g., Raw Materials, Work in Progress, Finished Goods, Spare Parts, Consumables)\n",
    "    - proportionality = share of total inventory value (0–1 range)\n",
    "\n",
    "    Rules:\n",
    "    - Must map logically to balance sheet accounts of type \"Inventory\".\n",
    "    - Include tangible goods (raw materials, semi-finished, finished goods, packaging, spare parts, etc.)\n",
    "      and work-in-progress where relevant.\n",
    "    - Reflect realistic items for the company's industry and geography.\n",
    "    - Rank by proportionality (descending).\n",
    "    - Avoid vague or generic terms such as \"Other inventory\" or \"Miscellaneous stock\".\n",
    "\n",
    "    {constraints}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful ERP and finance domain assistant who outputs clean CSV tables for balance sheet data models.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=temp,\n",
    "    )\n",
    "\n",
    "    df_inventory = prompt_utils.parse_and_truncate_csv(response.choices[0].message.content, count)\n",
    "\n",
    "    # Assign unique IDs\n",
    "    df_inventory.insert(0, \"inventory_id\", range(300, 300 + len(df_inventory)))\n",
    "\n",
    "    # Normalize proportionalities to sum to 1.0\n",
    "    df_inventory = utils.convert_column_to_percentage(df_inventory, \"proportionality\", scale=1.0)\n",
    "\n",
    "    return df_inventory\n",
    "\n",
    "\n",
    "def tailor_coa_to_lego(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    replacements = {\n",
    "        \"Raw Materials\": \"ABS Plastic & Pigments\",\n",
    "        \"Finished Goods\": \"Finished LEGO Sets\",\n",
    "        \"Work in Progress\": \"Moulding & Assembly in Progress\",\n",
    "        \"Buildings & Improvements\": \"LEGO Factories & Warehouses\",\n",
    "        \"Leasehold Improvements\": \"Retail Store Fit-outs\",\n",
    "        \"Machinery & Equipment\": \"Moulding Machines & Production Lines\",\n",
    "        \"Retail Gross Sales\": \"LEGO Retail Store Sales\",\n",
    "        \"Trade Gross Sales\": \"Wholesale Channel Sales\",\n",
    "        \"Retail COS\": \"Production Cost – Retail\",\n",
    "        \"Trade COS\": \"Manufacturing Cost – Trade\",\n",
    "        \"Marketing Collateral\": \"Packaging & Campaign Materials\",\n",
    "        \"Other Income\": \"Royalty & Licensing Income\",\n",
    "    }\n",
    "    df[\"AccountDescription\"] = df[\"AccountDescription\"].replace(replacements)\n",
    "    df[\"GLLevel05\"] = df[\"GLLevel05\"].replace(replacements)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0896152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_PROMPT = \"\"\"\n",
    "You are a financial controller generating a realistic analytical spend dataset for a company.\n",
    "\n",
    "### INPUT DATA\n",
    "Company: {company_name}\n",
    "\n",
    "Financial Totals (DKK):\n",
    "- Revenue: {revenue_value}\n",
    "- COGS: {cogs_value}\n",
    "- Gross Profit: {gross_profit_value}\n",
    "- Fixed Cost: {fixed_cost_value}\n",
    "- EBIT: {ebit_value}\n",
    "\n",
    "Chart of Accounts (CoA):\n",
    "{coa_list}\n",
    "\n",
    "Row Counts:\n",
    "- Revenue rows: {revenue_rows}\n",
    "- COGS rows: {cogs_rows}\n",
    "- FixedCost rows: {fixedcost_rows}\n",
    "- EBIT rows: {ebit_rows}\n",
    "\n",
    "### TASK\n",
    "Generate a semicolon-delimited CSV table where each row represents one analytical line item of the company's general ledger.\n",
    "The dataset must:\n",
    "1. Follow the structure of the provided CoA.\n",
    "2. Respect the exact totals above (sum per category equals the financial total).\n",
    "3. Contain exactly the specified number of rows per category.\n",
    "4. Include realistic business units, customers, and vendors relevant to the specific company and industry.\n",
    "\n",
    "---\n",
    "\n",
    "### RULES\n",
    "\n",
    "**Columns**\n",
    "company;business_unit;account_number;account_name;item_name;customer;vendor;amount_DKK;category\n",
    "\n",
    "**Account Mapping**\n",
    "- Revenue → 4001–4009  \n",
    "- COGS → 4003, 4006, 4009  \n",
    "- FixedCost → 5001–5027  \n",
    "- EBIT → 6001–6503  \n",
    "\n",
    "**Category Logic**\n",
    "- **Revenue**: Product or service sales.  \n",
    "  - For intercompany accounts (4007–4008), `customer` is an internal business unit.  \n",
    "  - For other accounts, `customer` is an external distributor or partner relevant to the company.  \n",
    "- **COGS**: Production, materials, and logistics.  \n",
    "  - For intercompany COGS (4009), `vendor` is an internal business unit.  \n",
    "  - Otherwise, use external suppliers typical for the company's industry.  \n",
    "- **FixedCost**: Overhead (salaries, marketing, rent, utilities, travel, consulting).  \n",
    "- **EBIT**: Other income/expenses (interest, exchange differences, royalties, etc.).  \n",
    "\n",
    "**Business Units**\n",
    "Generate 10 realistic business units for the specific company (factories, sales regions, HQs, divisions, etc.).  \n",
    "Example:\n",
    "- For LEGO → LEGO Retail DK, LEGO Factory CZ, LEGO HQ Billund  \n",
    "- For Arla → Arla Foods DK, Arla UK, Arla Ingredients  \n",
    "- For Biocirc → Biocirc Odense, Biocirc Kalundborg, Biocirc HQ Copenhagen  \n",
    "\n",
    "Use them consistently for internal transactions.\n",
    "\n",
    "**Value Distribution**\n",
    "Randomize amounts while ensuring that:\n",
    "- Each category sums exactly to its total value.\n",
    "- Variation is realistic (a few large values, many smaller).\n",
    "\n",
    "---\n",
    "\n",
    "### OUTPUT FORMAT\n",
    "Return **only the CSV content**, starting with a header and using `;` as delimiter:\n",
    "company;business_unit;account_number;account_name;item_name;customer;vendor;amount_DKK;category\n",
    "Do not include explanations, markdown, or extra text—only the CSV table.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "prompt = MASTER_PROMPT.format(\n",
    "    company_name=\"LEGO\",\n",
    "    revenue_value=102709000,\n",
    "    cogs_value=-80578387,\n",
    "    gross_profit_value=22130526,\n",
    "    fixed_cost_value=-17916252,\n",
    "    ebit_value=4214272,\n",
    "    coa_list=\"coa_text\",\n",
    "    revenue_rows=100,\n",
    "    cogs_rows=100,\n",
    "    fixedcost_rows=50,\n",
    "    ebit_rows=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11d2f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from generators.llm_generators import tailor_coa_names_llm\n",
    "\n",
    "df_accounts = pd.read_csv(\"data/inputdata/coa_general.csv\", sep = \";\")\n",
    "df_coa = tailor_coa_names_llm(df_accounts, company_name=\"Lego\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b233e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TAILOR_COA = \"\"\"\n",
    "You are a corporate finance specialist adapting a Chart of Accounts to a specific company.\n",
    "\n",
    "Company: {company_name}\n",
    "\n",
    "Input Chart of Accounts:\n",
    "{coa_list}\n",
    "\n",
    "Task:\n",
    "Rewrite the account descriptions and relevant GLLevel04–GLLevel05 fields to reflect this company's industry and operations.\n",
    "Keep every column name and key exactly as provided.\n",
    "Do not remove or add rows.\n",
    "\n",
    "Output:\n",
    "Return only a semicolon-separated CSV with identical columns.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_BUSINESS_UNITS = \"\"\"\n",
    "You are designing a realistic company structure.\n",
    "\n",
    "Company: {company_name}\n",
    "\n",
    "Task:\n",
    "Generate 10–15 business units and departments that reflect this company’s operations.\n",
    "For each, include:\n",
    "BU_ID;BU_Name;BU_Type;Department;Country;Description\n",
    "\n",
    "BU_Type examples: Factory, Retail, HQ, Licensing, Shared Service, Online.\n",
    "\n",
    "Output:\n",
    "Return only a semicolon-separated CSV with the columns above.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_PARTIES = \"\"\"\n",
    "You are populating master data for external and internal counterparties.\n",
    "\n",
    "Company: {company_name}\n",
    "\n",
    "Input Business Units:\n",
    "{bu_list}\n",
    "\n",
    "Task:\n",
    "Generate 10–20 external customers and 10–20 external vendors, plus all internal business units as internal parties.\n",
    "\n",
    "Columns:\n",
    "Party_ID;Party_Name;Party_Type;Country;Description\n",
    "\n",
    "Where Party_Type ∈ {INTERNAL_BU, CUSTOMER, VENDOR}.\n",
    "Use internal BUs from the list above for Party_Type=INTERNAL_BU.\n",
    "\n",
    "Output:\n",
    "Return only a semicolon-separated CSV.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_LINES = \"\"\"\n",
    "You are generating detailed GL line items for synthetic analytical spend data.\n",
    "\n",
    "Company: {company_name}\n",
    "\n",
    "Financial total (DKK): {financial_total}\n",
    "Category: {category_name}\n",
    "Number of rows: {row_count}\n",
    "\n",
    "Input context:\n",
    "Chart of Accounts (relevant subset):\n",
    "{coa_subset}\n",
    "\n",
    "Business Units (IDs & Names):\n",
    "{bu_list}\n",
    "\n",
    "Parties (Customers/Vendors):\n",
    "{party_list}\n",
    "\n",
    "Task:\n",
    "Generate {row_count} detailed GL rows for the {category_name} category, that sum exactly to {financial_total} DKK.\n",
    "\n",
    "Rules:\n",
    "- Use only account_numbers from the provided CoA subset.\n",
    "- Reference valid BU_ID and Party_ID.\n",
    "- Each row must include:\n",
    "  document_number;posting_date;company;BU_ID;Party_ID;account_number;account_name;item_name;amount_DKK;category\n",
    "- posting_date: random across 2024.\n",
    "- document_number: DOC000001 … sequential.\n",
    "- Intercompany lines must use internal BUs for Party_ID.\n",
    "\n",
    "Output:\n",
    "Return only a semicolon-separated CSV with the columns above.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36956c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_BUSINESS_UNITS = \"\"\"\n",
    "You are creating a realistic internal org structure for a company.\n",
    "\n",
    "Company: {company_name}\n",
    "\n",
    "Task:\n",
    "Generate 10-15 business units and departments that reflect how this company would actually operate (production sites, regional sales orgs, HQ functions, logistics hubs, shared services, etc.).\n",
    "\n",
    "Return ONLY a semicolon-separated CSV with the following columns in this exact order:\n",
    "BU_ID;BU_Name;BU_Type;Department;Country;Description\n",
    "\n",
    "Definitions:\n",
    "- BU_ID: stable ID like BU001, BU002, ...\n",
    "- BU_Name: human label, e.g. \"LEGO Retail DK\", \"LEGO Factory CZ\", \"LEGO HQ Billund\"\n",
    "- BU_Type: one of [Factory, Retail, HQ, Licensing, Shared Service, Online, Distribution]\n",
    "- Department: e.g. \"Sales\", \"Manufacturing\", \"Finance\", \"Marketing\", \"Logistics\", \"IT\"\n",
    "- Country: realistic country/region for that BU\n",
    "- Description: short purpose of this unit\n",
    "\n",
    "Rules:\n",
    "- Make sure there is at least one HQ / corporate finance unit.\n",
    "- Make sure there are both commercial (sales/retail) and production/supply-side units.\n",
    "- IDs must be unique.\n",
    "- Do not include any extra commentary, only the CSV.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b96300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_PARTIES = \"\"\"\n",
    "You are creating master data for all counterparties involved in billing and cost of goods.\n",
    "\n",
    "Company: {company_name}\n",
    "\n",
    "Here is the list of internal business units for this company:\n",
    "{business_units_csv}\n",
    "\n",
    "Task:\n",
    "1. For each internal BU above, create a row where that BU is a party.\n",
    "2. Create 10-20 external customers (distributors, retailers, key accounts, web shop channels).\n",
    "3. Create 10-20 external vendors (material suppliers, logistics providers, energy providers, maintenance contractors).\n",
    "\n",
    "Return ONLY a semicolon-separated CSV with the following columns in this exact order:\n",
    "Party_ID;Party_Name;Party_Type;Country;Description\n",
    "\n",
    "Where:\n",
    "- Party_ID:\n",
    "  - INTERNAL_BU should start with \"INT\" (e.g. INT001)\n",
    "  - CUSTOMER should start with \"CUST\" (e.g. CUST001)\n",
    "  - VENDOR should start with \"VEND\" (e.g. VEND001)\n",
    "- Party_Type is one of [INTERNAL_BU, CUSTOMER, VENDOR]\n",
    "- Country and Description should be realistic\n",
    "- Party_Name MUST stay stable and professional (e.g. \"Amazon EU Retail\", \"Maersk Logistics DK\", \"LEGO Retail DK\")\n",
    "\n",
    "Rules:\n",
    "- For INTERNAL_BU parties, Party_Name should exactly match the BU_Name from the input business units.\n",
    "- INTERNAL_BU rows must cover ALL input BU_IDs.\n",
    "- Do not include any extra commentary, only the CSV.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca05029",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_LINES = \"\"\"\n",
    "You are generating detailed GL/transaction lines for synthetic financial data.\n",
    "\n",
    "Company: {company_name}\n",
    "Category to generate: {category_name}        # e.g. Revenue, COGS, FixedCost, EBIT\n",
    "Target total for this category (DKK): {financial_total}\n",
    "Number of rows to generate: {row_count}\n",
    "\n",
    "ACCOUNTS (only use these AccountKeys for this category):\n",
    "AccountKey;name\n",
    "{accounts_subset_csv}\n",
    "\n",
    "BUSINESS UNITS (use these BU_IDs only):\n",
    "BU_ID;BU_Name;BU_Type;Department;Country;Description\n",
    "{business_units_csv}\n",
    "\n",
    "PARTIES (customers, vendors, internal units):\n",
    "Party_ID;Party_Name;Party_Type;Country;Description\n",
    "{parties_csv}\n",
    "\n",
    "Your task:\n",
    "Generate {row_count} GL line items for the given category {category_name}.\n",
    "The sum of 'amount_DKK' over ALL {row_count} rows MUST equal {financial_total} exactly.\n",
    "\n",
    "Output a semicolon-separated CSV with columns in this exact order:\n",
    "document_number;posting_date;company;BU_ID;Party_ID;AccountKey;AccountName;item_name;amount_DKK;category\n",
    "\n",
    "Column definitions:\n",
    "- document_number: sequential, zero-padded: DOC000001, DOC000002, ...\n",
    "- posting_date: realistic YYYY-MM-DD dates across the year 2024\n",
    "- company: literal company name\n",
    "- BU_ID: must match one of the BU_ID values from the business units table\n",
    "- Party_ID:\n",
    "  - For Revenue:\n",
    "    - If AccountKey is an intercompany revenue account (e.g. \"Inter Company Gross Sales\"), Party_ID must be an INTERNAL_BU.\n",
    "    - Otherwise use CUSTOMER.\n",
    "  - For COGS:\n",
    "    - If AccountKey is an intercompany COGS account, Party_ID must be an INTERNAL_BU.\n",
    "    - Otherwise use VENDOR.\n",
    "  - For FixedCost and EBIT:\n",
    "    - Party_ID can be blank unless it clearly represents a counterparty (like external legal services).\n",
    "- AccountKey: must be copied from the provided accounts list\n",
    "- AccountName: must be copied from the 'name' column for that AccountKey\n",
    "- item_name: human-readable description of what the line is (examples: \"ABS plastic pellets\", \"Retail set sales - City/Police Station\", \"Factory utilities Denmark\", \"Royalty income from licensing\")\n",
    "- amount_DKK: numeric, can be positive or negative depending on category\n",
    "- category: must match {category_name} exactly\n",
    "\n",
    "Rules:\n",
    "- DO NOT invent new AccountKeys. Only use the provided ones.\n",
    "- DO NOT invent new BU_IDs or Party_IDs. Only use the provided ones.\n",
    "- Make item_name specific and believable for this industry.\n",
    "- The sum of all amount_DKK in this output must equal {financial_total} exactly.\n",
    "- You must return EXACTLY {row_count} rows.\n",
    "- Do not include any commentary, markdown, headers before the header row etc.\n",
    "\n",
    "Return ONLY the CSV.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cogs_items_llm(company_name: str, \n",
    "                            count: int = 100, \n",
    "                            category_name: str = \"COGS\", \n",
    "                            financial_total: float = 100000.0, \n",
    "                            business_units_csv: str = \"\",\n",
    "                            parties_csv: str = \"\",\n",
    "                            accounts_subset_csv: str = \"\",\n",
    "                            model: str = \"gpt-4.1\", \n",
    "                            temp: float = 0.8):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate COGS (Cost of Goods Sold) items for a company.\n",
    "    Each item should map to Product Expense or Service Expense accounts in the COA.\n",
    "    \"\"\"\n",
    "\n",
    "    client = prompt_utils.get_openai_client()\n",
    "    over_request_count = int(np.floor(int(count) * 1.4))\n",
    "\n",
    "    header = \"name;cogs_segment;proportionality\"\n",
    "    constraints = prompt_utils.get_standard_constraints(header, over_request_count)\n",
    "    ctxb = prompt_utils._ctx_block(company_name)\n",
    "\n",
    "    PROMPT_LINES = f\"\"\"\n",
    "    You are generating detailed GL/transaction lines for synthetic financial data.\n",
    "\n",
    "    Company: {company_name}\n",
    "    Category to generate: {category_name}        # e.g. Revenue, COGS, FixedCost, EBIT\n",
    "    Target total for this category (DKK): {financial_total}\n",
    "    Number of rows to generate: {over_request_count}\n",
    "\n",
    "    ACCOUNTS (only use these AccountKeys for this category):\n",
    "    AccountKey;name\n",
    "    {accounts_subset_csv}\n",
    "\n",
    "    BUSINESS UNITS (use these BU_IDs only):\n",
    "    BU_ID;BU_Name;BU_Type;Department;Country;Description\n",
    "    {business_units_csv}\n",
    "\n",
    "    PARTIES (customers, vendors, internal units):\n",
    "    Party_ID;Party_Name;Party_Type;Country;Description\n",
    "    {parties_csv}\n",
    "\n",
    "    Your task:\n",
    "    Generate {over_request_count} GL line items for the given category {category_name}.\n",
    "    The sum of 'amount_DKK' over ALL {over_request_count} rows MUST equal {financial_total} exactly.\n",
    "\n",
    "    Output a semicolon-separated CSV with columns in this exact order:\n",
    "    document_number;posting_date;company;BU_ID;Party_ID;AccountKey;AccountName;item_name;amount_DKK;category\n",
    "\n",
    "    Column definitions:\n",
    "    - document_number: sequential, zero-padded: DOC000001, DOC000002, ...\n",
    "    - posting_date: realistic YYYY-MM-DD dates across the year 2024\n",
    "    - company: literal company name\n",
    "    - BU_ID: must match one of the BU_ID values from the business units table\n",
    "    - Party_ID:\n",
    "    - For Revenue:\n",
    "        - If AccountKey is an intercompany revenue account (e.g. \"Inter Company Gross Sales\"), Party_ID must be an INTERNAL_BU.\n",
    "        - Otherwise use CUSTOMER.\n",
    "    - For COGS:\n",
    "        - If AccountKey is an intercompany COGS account, Party_ID must be an INTERNAL_BU.\n",
    "        - Otherwise use VENDOR.\n",
    "    - For FixedCost and EBIT:\n",
    "        - Party_ID can be blank unless it clearly represents a counterparty (like external legal services).\n",
    "    - AccountKey: must be copied from the provided accounts list\n",
    "    - AccountName: must be copied from the 'name' column for that AccountKey\n",
    "    - item_name: human-readable description of what the line is (examples: \"ABS plastic pellets\", \"Retail set sales - City/Police Station\", \"Factory utilities Denmark\", \"Royalty income from licensing\")\n",
    "    - amount_DKK: numeric, can be positive or negative depending on category\n",
    "    - category: must match {category_name} exactly\n",
    "\n",
    "    Rules:\n",
    "    - DO NOT invent new AccountKeys. Only use the provided ones.\n",
    "    - DO NOT invent new BU_IDs or Party_IDs. Only use the provided ones.\n",
    "    - Make item_name specific and believable for this industry.\n",
    "    - The sum of all amount_DKK in this output must equal {financial_total} exactly.\n",
    "    - You must return EXACTLY {over_request_count} rows.\n",
    "    - Do not include any commentary, markdown, headers before the header row etc.\n",
    "\n",
    "    Return ONLY the CSV.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful financial analyst and ERP mapping assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=temp,\n",
    "    )\n",
    "\n",
    "    df_cogs = prompt_utils.parse_and_truncate_csv(response.choices[0].message.content, count)\n",
    "\n",
    "    # Add unique IDs for the COGS items\n",
    "    df_cogs.insert(0, \"cogs_id\", range(200, len(df_cogs) + 200))\n",
    "\n",
    "    # Normalize proportionalities\n",
    "    df_cogs = utils.convert_column_to_percentage(df_cogs, \"proportionality\", scale=1.0)\n",
    "\n",
    "    return df_cogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from utils import prompt_utils\n",
    "#from utils.utils import convert_column_to_percentage\n",
    "#from llm_generation.prompts import PROMPT_BUSINESS_UNITS, PROMPT_PARTIES, PROMPT_LINES\n",
    "#from utils.prompts import call_llm_prompt  # your existing function\n",
    "\n",
    "# helper to convert df to ; separated text\n",
    "def df_to_semicolon_csv(df: pd.DataFrame) -> str:\n",
    "    return df.to_csv(index=False, sep=\";\")\n",
    "\n",
    "def generate_business_units(company_name: str) -> pd.DataFrame:\n",
    "    prompt = PROMPT_BUSINESS_UNITS.format(company_name=company_name)\n",
    "    return call_llm_prompt(prompt, prompt, count=20)\n",
    "\n",
    "def generate_parties(company_name: str, bu_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    prompt = PROMPT_PARTIES.format(\n",
    "        company_name=company_name,\n",
    "        business_units_csv=df_to_semicolon_csv(bu_df)\n",
    "    )\n",
    "    return call_llm_prompt(prompt, count=60)\n",
    "\n",
    "def generate_category_lines(\n",
    "    company_name: str,\n",
    "    category_name: str,\n",
    "    financial_total: float,\n",
    "    row_count: int,\n",
    "    accounts_subset_df: pd.DataFrame,\n",
    "    bu_df: pd.DataFrame,\n",
    "    parties_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    prompt = PROMPT_LINES.format(\n",
    "        company_name=company_name,\n",
    "        category_name=category_name,\n",
    "        financial_total=financial_total,\n",
    "        row_count=row_count,\n",
    "        accounts_subset_csv=df_to_semicolon_csv(accounts_subset_df[[\"AccountKey\",\"name\"]]),\n",
    "        business_units_csv=df_to_semicolon_csv(bu_df),\n",
    "        parties_csv=df_to_semicolon_csv(parties_df)\n",
    "    )\n",
    "    return call_llm_prompt(prompt, count=row_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e62239c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vendors_llm(company_name: str, count: int = 100, model: str = \"gpt-4.1\", temp: float = 0.8):\n",
    "    client = prompt_utils.get_openai_client()\n",
    "    over_request_count = int(np.floor(int(count) * 1.4))\n",
    "    header = \"name;vendor_type;proportionality\"\n",
    "    constraints = prompt_utils.get_standard_constraints(header, over_request_count)\n",
    "    ctxb = prompt_utils._ctx_block(company_name)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a B2B procurement and supply chain expert. Generate {over_request_count} realistic vendors for {company_name}.\n",
    "    Fields:\n",
    "    - name\n",
    "    - vendor_type: Raw Materials, Equipment, IT Services, Logistics, Facilities, Office Supplies, Contract Labor, Consulting\n",
    "    - proportionality: the proportionality of this vendor.\n",
    "    Bias critical categories and concentration based on the context.\n",
    "\n",
    "    {constraints}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful data assistant and B2B vendor segmentation expert.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temp,\n",
    "    )\n",
    "    df_vendors = prompt_utils.parse_and_truncate_csv(response.choices[0].message.content, count)\n",
    "    df_vendors.insert(0, \"vendor_id\", range(20, len(df_vendors) + 20))\n",
    "    df_vendors = utils.convert_column_to_percentage(df_vendors, \"proportionality\", scale=1.0)\n",
    "    return df_vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2a261be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_prompt(\n",
    "    prompt: str,\n",
    "    model: str = \"gpt-4.1\",\n",
    "    temp: float = 0.8,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Executes a given prompt and returns the raw model text output.\n",
    "    No parsing. No truncation.\n",
    "    \"\"\"\n",
    "    client = prompt_utils.get_openai_client()\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a financial controller generating realistic GL items.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt.strip()\n",
    "            },\n",
    "        ],\n",
    "        temperature=temp,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a7c6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def call_llm_overrequest(\n",
    "    prompt_template: str,\n",
    "    prompt_kwargs: dict,\n",
    "    count: int,\n",
    "    model: str = \"gpt-5\",\n",
    "    temp: float = 1,\n",
    "    over_factor: float = 1.4\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Renders the prompt, over-requests rows from the model,\n",
    "    parses them, and returns a df with exactly `count` rows\n",
    "    (or raises if even that is impossible).\n",
    "    \"\"\"\n",
    "    # how many rows we *ask* the LLM for\n",
    "    over_request_count = int(np.floor(int(count) * over_factor))\n",
    "\n",
    "    # inject both requested count and over_request_count into the prompt\n",
    "    full_prompt = prompt_template.format(\n",
    "        **prompt_kwargs,\n",
    "        count=count,\n",
    "        over_request_count=over_request_count,\n",
    "    )\n",
    "\n",
    "    # 1) get raw text from LLM\n",
    "    raw_text = call_llm_prompt(\n",
    "        prompt=full_prompt,\n",
    "        model=model,\n",
    "        temp=temp,\n",
    "    )\n",
    "\n",
    "    # 2) parse whatever it gave us into a df\n",
    "    # IMPORTANT: we pass over_request_count here because that's the \"max rows\" we\n",
    "    # tried to ask for. parse_and_truncate_csv should NOT raise hard if it's short.\n",
    "    df_full = prompt_utils.parse_and_truncate_csv(\n",
    "        raw_text,\n",
    "        over_request_count\n",
    "    )\n",
    "\n",
    "    # 3) sanity check: did we at least get `count` usable rows?\n",
    "    if len(df_full) < count:\n",
    "        raise ValueError(\n",
    "            f\"LLM underfilled: needed {count} rows but only got {len(df_full)} usable rows \"\n",
    "            f\"after requesting {over_request_count}.\"\n",
    "        )\n",
    "\n",
    "    # 4) now truncate to exactly the number the caller wanted\n",
    "    df = df_full.head(count).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a0a2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_BUSINESS_UNITS = \"\"\"\n",
    "You are creating a realistic internal org structure for a company.\n",
    "\n",
    "Company: {company_name}\n",
    "\n",
    "Task:\n",
    "Generate {over_request_count} business units / departments that reflect how this company operates\n",
    "(production sites, regional sales orgs, HQ functions, logistics hubs, shared services, etc.).\n",
    "\n",
    "Return ONLY a semicolon-separated CSV with the following columns in this exact order:\n",
    "BU_ID;BU_Name;BU_Type;Department;Country,Company_ID\n",
    "\n",
    "Rules:\n",
    "- BU_ID: stable ID like BU001, BU002, ...\n",
    "- BU_Type: one of [Factory, Retail, HQ, Licensing, Shared Service, Online, Distribution]\n",
    "- At least one HQ / Corporate / Finance function must exist.\n",
    "- Include both commercial (sales/retail) and production/supply-side units.\n",
    "- IDs must be unique.\n",
    "- For each Unique country there should be a unique companyID. Start with 1000.\n",
    "- Do not add commentary or markdown, only the CSV.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4fe8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_business_units(company_name: str,\n",
    "                            count: int = 15,\n",
    "                            model: str = \"gpt-5\",\n",
    "                            temp: float = 1) -> pd.DataFrame:\n",
    "    prompt_kwargs = {\n",
    "        \"company_name\": company_name,\n",
    "    }\n",
    "    df_bu = call_llm_overrequest(\n",
    "        prompt_template=PROMPT_BUSINESS_UNITS,\n",
    "        prompt_kwargs=prompt_kwargs,\n",
    "        count=count,\n",
    "        model=model,\n",
    "        temp=temp,\n",
    "        over_factor=1.4\n",
    "    )\n",
    "    return df_bu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc7b976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_PARTIES = \"\"\"\n",
    "You are creating master data for all counterparties in this company.\n",
    "\n",
    "Company: {company_name}\n",
    "\n",
    "Internal business units (BU master data):\n",
    "{business_units_csv}\n",
    "\n",
    "Task:\n",
    "1. For each internal BU, create a row where that BU is treated as a party.\n",
    "2. Also create external customers (distributors, retailers, channels).\n",
    "3. Also create external vendors (materials suppliers, logistics, energy, maintenance, IT services).\n",
    "\n",
    "Generate {over_request_count} rows TOTAL across all types.\n",
    "\n",
    "Return ONLY a semicolon-separated CSV with columns in this exact order:\n",
    "Party_ID;Party_Name;Party_Type;Country\n",
    "\n",
    "Where:\n",
    "- Party_ID:\n",
    "  - INTERNAL_BU => \"INT###\"\n",
    "  - CUSTOMER    => \"CUST###\"\n",
    "  - VENDOR      => \"VEND###\"\n",
    "- Party_Type is exactly one of [INTERNAL_BU, CUSTOMER, VENDOR]\n",
    "- INTERNAL_BU rows must include ALL internal business units given above.\n",
    "- Party_Name for INTERNAL_BU must match BU_Name exactly.\n",
    "- No commentary, no markdown, only CSV.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ca4a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parties(\n",
    "    company_name: str,\n",
    "    bu_df: pd.DataFrame,\n",
    "    count: int = 40,\n",
    "    model: str = \"gpt-5\",\n",
    "    temp: float = 1\n",
    ") -> pd.DataFrame:\n",
    "    prompt_kwargs = {\n",
    "        \"company_name\": company_name,\n",
    "        \"business_units_csv\": bu_df.to_csv(index=False, sep=\";\"),\n",
    "    }\n",
    "\n",
    "    df_parties = call_llm_overrequest(\n",
    "        prompt_template=PROMPT_PARTIES,\n",
    "        prompt_kwargs=prompt_kwargs,\n",
    "        count=count,\n",
    "        model=model,\n",
    "        temp=temp,\n",
    "        over_factor=1.4,\n",
    "    )\n",
    "    return df_parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_LINES = \"\"\"\n",
    "You are generating detailed GL/transaction lines for synthetic financial data.\n",
    "\n",
    "Company: {company_name}\n",
    "Category to generate: {category_name}        \n",
    "Target total for this category (DKK): {financial_total}\n",
    "We ultimately need {count} rows, but you must generate {over_request_count} rows so we can select the best subset.\n",
    "\n",
    "ACCOUNTS (only use these AccountKeys for this category):\n",
    "AccountKey;name\n",
    "{accounts_subset_csv}\n",
    "\n",
    "BUSINESS UNITS (valid BU_IDs only):\n",
    "BU_ID;BU_Name;BU_Type;Department;Country;Description\n",
    "{business_units_csv}\n",
    "\n",
    "PARTIES (valid Party_IDs only):\n",
    "Party_ID;Party_Name;Party_Type;Country;Description\n",
    "{parties_csv}\n",
    "\n",
    "Task:\n",
    "Generate {over_request_count} GL line items for the given category {category_name}.\n",
    "The sum of 'amount_DKK' across ALL {over_request_count} rows MUST equal {financial_total} exactly.\n",
    "\n",
    "Output a semicolon-separated CSV with columns in this exact order:\n",
    "document_number;posting_date;company;BU_ID;Party_ID;AccountKey;AccountName;item_name;amount_DKK;category\n",
    "\n",
    "Column definitions:\n",
    "- document_number: sequential, zero-padded: 000001, 000002, ...\n",
    "- company: literal company name\n",
    "- BU_ID: must match one of the BU_ID values from the business units table\n",
    "- Party_ID:\n",
    "  - Revenue:\n",
    "    - If AccountKey relates to intercompany Revenue, Party_ID must be an INTERNAL_BU.\n",
    "    - Otherwise must be CUSTOMER.\n",
    "  - COGS:\n",
    "    - If AccountKey relates to intercompany COGS, Party_ID must be an INTERNAL_BU.\n",
    "    - Otherwise must be VENDOR.\n",
    "  - FixedCost and EBIT:\n",
    "    - Party_ID can be blank unless there's a clear external counterparty (e.g. law firm)\n",
    "- AccountKey: must come from ACCOUNTS section\n",
    "- AccountName: must be copied from 'name' in ACCOUNTS\n",
    "- item_name: specific and believable for this industry (materials, sets sold, marketing campaign, royalty income, etc.)\n",
    "- amount_DKK: numeric, signs consistent with category\n",
    "- category: must match {category_name} exactly\n",
    "\n",
    "Rules:\n",
    "- DO NOT invent new AccountKeys, BU_IDs, or Party_IDs.\n",
    "- You must return EXACTLY {over_request_count} rows.\n",
    "- The total sum of amount_DKK across ALL rows you output must equal {financial_total} exactly.\n",
    "- No commentary, markdown fences, or explanations. Only CSV.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9f65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_category_lines(\n",
    "    company_name: str,\n",
    "    category_name: str,\n",
    "    financial_total: float,\n",
    "    row_count: int,\n",
    "    accounts_subset_df: pd.DataFrame,\n",
    "    bu_df: pd.DataFrame,\n",
    "    parties_df: pd.DataFrame,\n",
    "    model: str = \"gpt-5\",\n",
    "    temp: float = 1,\n",
    "    over_factor: float = 1.4,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate granular line items for a given P&L category (e.g. 'Revenue').\n",
    "\n",
    "    - We call the LLM with overrequest, *but we will not die* if it returns\n",
    "      fewer than row_count rows. We'll pad ourselves.\n",
    "    - We then force the final df to have exactly `row_count` rows.\n",
    "    - Finally we reconcile amounts to sum to `financial_total`.\n",
    "    \"\"\"\n",
    "\n",
    "    desired_rows = int(row_count)\n",
    "\n",
    "    # --- 1. Prep prompt kwargs ---\n",
    "    accounts_subset_limited = accounts_subset_df.head(100).copy()\n",
    "\n",
    "    prompt_kwargs = {\n",
    "        \"company_name\": company_name,\n",
    "        \"category_name\": category_name,\n",
    "        \"financial_total\": financial_total,\n",
    "        \"accounts_subset_csv\": accounts_subset_limited[[\"AccountKey\", \"name\"]]\n",
    "            .to_csv(index=False, sep=\";\"),\n",
    "        \"business_units_csv\": bu_df.to_csv(index=False, sep=\";\"),\n",
    "        \"parties_csv\": parties_df.to_csv(index=False, sep=\";\"),\n",
    "    }\n",
    "\n",
    "    # --- 2. Call LLM (it will over-request internally), but DO NOT TRUST IT ---\n",
    "    try:\n",
    "        df_lines = call_llm_overrequest(\n",
    "            prompt_template=PROMPT_LINES,\n",
    "            prompt_kwargs=prompt_kwargs,\n",
    "            count=desired_rows,\n",
    "            model=model,\n",
    "            temp=temp,\n",
    "            over_factor=over_factor,\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # salvage mode:\n",
    "        # call_llm_overrequest is yelling \"Only received 139 rows, expected 140\"\n",
    "        # but it probably *has* the partial df somewhere before raising.\n",
    "        # If it doesn't expose that, we just retry a simpler call without over_factor\n",
    "        # and then continue. We MUST return *something*.\n",
    "        # We'll assume we can still query the model once without strict check.\n",
    "        # If you already have a \"bare\" LLM caller, plug it in here.\n",
    "        df_lines = basic_llm_call_no_overrequest(\n",
    "            prompt_template=PROMPT_LINES,\n",
    "            prompt_kwargs=prompt_kwargs,\n",
    "            count=desired_rows,\n",
    "            model=model,\n",
    "            temp=temp,\n",
    "        )\n",
    "\n",
    "        # If that still fails for some reason and gives nothing, create empty shell:\n",
    "        if df_lines is None or len(df_lines) == 0:\n",
    "            df_lines = pd.DataFrame(\n",
    "                [{\n",
    "                    \"description\": f\"{category_name} line {i+1}\",\n",
    "                    \"AccountKey\": None,\n",
    "                    \"BusinessUnit\": None,\n",
    "                    \"Counterparty\": None,\n",
    "                    \"amount_DKK\": 0.0,\n",
    "                } for i in range(desired_rows)]\n",
    "            )\n",
    "\n",
    "    # --- 3. Normalize/clean columns (especially amount) ---\n",
    "    def _clean(col):\n",
    "        return (\n",
    "            str(col)\n",
    "            .strip()\n",
    "            .lower()\n",
    "            .replace(\" \", \"_\")\n",
    "            .replace(\"-\", \"_\")\n",
    "        )\n",
    "\n",
    "    colmap_clean = { _clean(c): c for c in df_lines.columns }\n",
    "\n",
    "    amount_candidates_clean = [\n",
    "        \"amount_dkk\",\n",
    "        \"amount\",\n",
    "        \"dkk_amount\",\n",
    "        \"value_dkk\",\n",
    "        \"value\",\n",
    "        \"line_amount\",\n",
    "        \"line_value\",\n",
    "    ]\n",
    "\n",
    "    amount_col_original = None\n",
    "    for cand in amount_candidates_clean:\n",
    "        if cand in colmap_clean:\n",
    "            amount_col_original = colmap_clean[cand]\n",
    "            break\n",
    "\n",
    "    if amount_col_original is None:\n",
    "        # heuristic fallback: pick the numeric column with biggest absolute sum\n",
    "        numeric_cols = []\n",
    "        for c in df_lines.columns:\n",
    "            s_num = pd.to_numeric(df_lines[c], errors=\"coerce\")\n",
    "            if s_num.notna().any():\n",
    "                numeric_cols.append((c, s_num.abs().sum()))\n",
    "        if numeric_cols:\n",
    "            numeric_cols.sort(key=lambda x: x[1], reverse=True)\n",
    "            amount_col_original = numeric_cols[0][0]\n",
    "\n",
    "    if amount_col_original is not None:\n",
    "        df_lines[\"amount_DKK\"] = pd.to_numeric(\n",
    "            df_lines[amount_col_original], errors=\"coerce\"\n",
    "        ).fillna(0.0)\n",
    "    else:\n",
    "        df_lines[\"amount_DKK\"] = 0.0\n",
    "\n",
    "    # --- 4. Force EXACTLY desired_rows ---\n",
    "    if len(df_lines) > desired_rows:\n",
    "        # too many -> crop\n",
    "        df_lines = df_lines.iloc[:desired_rows].copy()\n",
    "\n",
    "    elif len(df_lines) < desired_rows:\n",
    "        if len(df_lines) == 0:\n",
    "            df_lines = pd.DataFrame(\n",
    "                [{\n",
    "                    \"description\": f\"{category_name} line {i+1}\",\n",
    "                    \"AccountKey\": None,\n",
    "                    \"BusinessUnit\": None,\n",
    "                    \"Counterparty\": None,\n",
    "                    \"Amount\": 0.0,\n",
    "                } for i in range(desired_rows)]\n",
    "            )\n",
    "        else:\n",
    "            last_row = df_lines.iloc[[-1]].copy()\n",
    "            last_row[\"Amount\"] = 0.0\n",
    "            pads_needed = desired_rows - len(df_lines)\n",
    "            pads = pd.concat([last_row.copy() for _ in range(pads_needed)],\n",
    "                             ignore_index=True)\n",
    "            df_lines = pd.concat([df_lines, pads], ignore_index=True)\n",
    "\n",
    "    # safety assert: if this trips something is *really* off\n",
    "    if len(df_lines) != desired_rows:\n",
    "        raise RuntimeError(\n",
    "            f\"After salvage/pad we still don't have {desired_rows} rows \"\n",
    "            f\"(got {len(df_lines)})\"\n",
    "        )\n",
    "\n",
    "    # --- 5. Reconcile numeric amounts to financial_total ---\n",
    "    df_lines[\"Amount\"] = pd.to_numeric(\n",
    "        df_lines[\"Amount\"], errors=\"coerce\"\n",
    "    ).fillna(0.0)\n",
    "\n",
    "    current_sum = float(df_lines[\"Amount\"].sum())\n",
    "\n",
    "    if current_sum != 0:\n",
    "        scale = float(financial_total) / current_sum\n",
    "        df_lines[\"Amount\"] = df_lines[\"Amount\"] * scale\n",
    "    else:\n",
    "        if financial_total != 0 and desired_rows > 0:\n",
    "            even_share = float(financial_total) / float(desired_rows)\n",
    "            df_lines[\"Amount\"] = even_share\n",
    "\n",
    "    df_lines[\"Amount\"] = df_lines[\"Amount\"].round(2)\n",
    "\n",
    "    final_sum_after_round = float(df_lines[\"Amount\"].sum())\n",
    "    diff = float(financial_total) - final_sum_after_round\n",
    "    if desired_rows > 0:\n",
    "        df_lines.loc[desired_rows - 1, \"Amount\"] += diff\n",
    "\n",
    "    df_lines = df_lines.reset_index(drop=True)\n",
    "\n",
    "    return df_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e546aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BU_ID                              BU_Name         BU_Type  \\\n",
      "0  BU001              LEGO Group Headquarters              HQ   \n",
      "1  BU002  Global Finance & Controlling Center  Shared Service   \n",
      "2  BU003        Global IT & Digital Platforms  Shared Service   \n",
      "3  BU004   Product Design & Innovation Studio              HQ   \n",
      "4  BU005            Billund Molding & Tooling         Factory   \n",
      "\n",
      "                Department  Country  Company_ID  \n",
      "0       Corporate Strategy  Denmark        1000  \n",
      "1  Finance Shared Services  Denmark        1000  \n",
      "2   Information Technology  Denmark        1000  \n",
      "3             Design & R&D  Denmark        1000  \n",
      "4        Injection Molding  Denmark        1000  \n"
     ]
    }
   ],
   "source": [
    "# === Step 1: load your general df_accounts ===\n",
    "#df_accounts = pd.read_csv(\"path/to/df_accounts.csv\", sep=\";\")\n",
    "df_accounts = df_coa.copy()\n",
    "\n",
    "# === Step 2: Generate Business Units ===\n",
    "company_name = \"LEGO\"\n",
    "bu_df = generate_business_units(company_name)\n",
    "print(bu_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f7e00ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BU_ID</th>\n",
       "      <th>BU_Name</th>\n",
       "      <th>BU_Type</th>\n",
       "      <th>Department</th>\n",
       "      <th>Country</th>\n",
       "      <th>Company_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BU001</td>\n",
       "      <td>LEGO Group Headquarters</td>\n",
       "      <td>HQ</td>\n",
       "      <td>Corporate Strategy</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BU002</td>\n",
       "      <td>Global Finance &amp; Controlling Center</td>\n",
       "      <td>Shared Service</td>\n",
       "      <td>Finance Shared Services</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BU003</td>\n",
       "      <td>Global IT &amp; Digital Platforms</td>\n",
       "      <td>Shared Service</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BU004</td>\n",
       "      <td>Product Design &amp; Innovation Studio</td>\n",
       "      <td>HQ</td>\n",
       "      <td>Design &amp; R&amp;D</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BU005</td>\n",
       "      <td>Billund Molding &amp; Tooling</td>\n",
       "      <td>Factory</td>\n",
       "      <td>Injection Molding</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BU006</td>\n",
       "      <td>Kladno Packaging Plant</td>\n",
       "      <td>Factory</td>\n",
       "      <td>Packaging &amp; Decoration</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BU007</td>\n",
       "      <td>Central Europe Distribution Hub - Prague</td>\n",
       "      <td>Distribution</td>\n",
       "      <td>Regional Distribution</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BU008</td>\n",
       "      <td>Nyíregyháza Manufacturing</td>\n",
       "      <td>Factory</td>\n",
       "      <td>Assembly &amp; Packaging</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BU009</td>\n",
       "      <td>Monterrey Manufacturing Campus</td>\n",
       "      <td>Factory</td>\n",
       "      <td>Injection Molding</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BU010</td>\n",
       "      <td>Monterrey Americas Distribution Center</td>\n",
       "      <td>Distribution</td>\n",
       "      <td>Regional Distribution</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BU011</td>\n",
       "      <td>Jiaxing Manufacturing</td>\n",
       "      <td>Factory</td>\n",
       "      <td>Molding &amp; Decoration</td>\n",
       "      <td>China</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BU012</td>\n",
       "      <td>Asia-Pacific Regional Sales HQ</td>\n",
       "      <td>HQ</td>\n",
       "      <td>Regional Sales</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BU013</td>\n",
       "      <td>China Retail Cluster</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail Operations</td>\n",
       "      <td>China</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BU014</td>\n",
       "      <td>North America Regional HQ</td>\n",
       "      <td>HQ</td>\n",
       "      <td>Regional Sales &amp; Marketing</td>\n",
       "      <td>United States</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BU015</td>\n",
       "      <td>US E-commerce Operations</td>\n",
       "      <td>Online</td>\n",
       "      <td>E-commerce Operations</td>\n",
       "      <td>United States</td>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BU_ID                                   BU_Name         BU_Type  \\\n",
       "0   BU001                   LEGO Group Headquarters              HQ   \n",
       "1   BU002       Global Finance & Controlling Center  Shared Service   \n",
       "2   BU003             Global IT & Digital Platforms  Shared Service   \n",
       "3   BU004        Product Design & Innovation Studio              HQ   \n",
       "4   BU005                 Billund Molding & Tooling         Factory   \n",
       "5   BU006                    Kladno Packaging Plant         Factory   \n",
       "6   BU007  Central Europe Distribution Hub - Prague    Distribution   \n",
       "7   BU008                 Nyíregyháza Manufacturing         Factory   \n",
       "8   BU009            Monterrey Manufacturing Campus         Factory   \n",
       "9   BU010    Monterrey Americas Distribution Center    Distribution   \n",
       "10  BU011                     Jiaxing Manufacturing         Factory   \n",
       "11  BU012            Asia-Pacific Regional Sales HQ              HQ   \n",
       "12  BU013                      China Retail Cluster          Retail   \n",
       "13  BU014                 North America Regional HQ              HQ   \n",
       "14  BU015                  US E-commerce Operations          Online   \n",
       "\n",
       "                    Department         Country  Company_ID  \n",
       "0           Corporate Strategy         Denmark        1000  \n",
       "1      Finance Shared Services         Denmark        1000  \n",
       "2       Information Technology         Denmark        1000  \n",
       "3                 Design & R&D         Denmark        1000  \n",
       "4            Injection Molding         Denmark        1000  \n",
       "5       Packaging & Decoration  Czech Republic        1001  \n",
       "6        Regional Distribution  Czech Republic        1001  \n",
       "7         Assembly & Packaging         Hungary        1002  \n",
       "8            Injection Molding          Mexico        1003  \n",
       "9        Regional Distribution          Mexico        1003  \n",
       "10        Molding & Decoration           China        1004  \n",
       "11              Regional Sales       Singapore        1005  \n",
       "12           Retail Operations           China        1004  \n",
       "13  Regional Sales & Marketing   United States        1006  \n",
       "14       E-commerce Operations   United States        1006  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77d5e8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Party_ID                           Party_Name   Party_Type  Country\n",
      "0   INT001              LEGO Group Headquarters  INTERNAL_BU  Denmark\n",
      "1   INT002  Global Finance & Controlling Center  INTERNAL_BU  Denmark\n",
      "2   INT003        Global IT & Digital Platforms  INTERNAL_BU  Denmark\n",
      "3   INT004   Product Design & Innovation Studio  INTERNAL_BU  Denmark\n",
      "4   INT005            Billund Molding & Tooling  INTERNAL_BU  Denmark\n"
     ]
    }
   ],
   "source": [
    "# === Step 3: Generate Master Parties ===\n",
    "parties_df = generate_parties(company_name, bu_df)\n",
    "print(parties_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c85a6964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only received 139 rows, expected 140\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# === Step 5: Run one category at a time ===\u001b[39;00m\n\u001b[32m     11\u001b[39m revenue_accounts = df_accounts[df_accounts[\u001b[33m\"\u001b[39m\u001b[33mAccountKey\u001b[39m\u001b[33m\"\u001b[39m].between(\u001b[32m4001\u001b[39m, \u001b[32m4009\u001b[39m)]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m revenue_df = \u001b[43mgenerate_category_lines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompany_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRevenue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinances\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRevenue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrows_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRevenue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevenue_accounts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbu_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparties_df\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mgenerate_category_lines\u001b[39m\u001b[34m(company_name, category_name, financial_total, row_count, accounts_subset_df, bu_df, parties_df, model, temp, over_factor)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# --- 2. Call LLM (it will over-request internally), but DO NOT TRUST IT ---\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     df_lines = \u001b[43mcall_llm_overrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPROMPT_LINES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdesired_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mover_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mover_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# salvage mode:\u001b[39;00m\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# call_llm_overrequest is yelling \"Only received 139 rows, expected 140\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# We'll assume we can still query the model once without strict check.\u001b[39;00m\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# If you already have a \"bare\" LLM caller, plug it in here.\u001b[39;00m\n\u001b[32m     57\u001b[39m     df_lines = basic_llm_call_no_overrequest(\n\u001b[32m     58\u001b[39m         prompt_template=PROMPT_LINES,\n\u001b[32m     59\u001b[39m         prompt_kwargs=prompt_kwargs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m         temp=temp,\n\u001b[32m     63\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mcall_llm_overrequest\u001b[39m\u001b[34m(prompt_template, prompt_kwargs, count, model, temp, over_factor)\u001b[39m\n\u001b[32m     37\u001b[39m df_full = prompt_utils.parse_and_truncate_csv(\n\u001b[32m     38\u001b[39m     raw_text,\n\u001b[32m     39\u001b[39m     over_request_count\n\u001b[32m     40\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# 3) sanity check: did we at least get `count` usable rows?\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_full\u001b[49m\u001b[43m)\u001b[49m < count:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     45\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLLM underfilled: needed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows but only got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_full)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m usable rows \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     46\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mafter requesting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mover_request_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     47\u001b[39m     )\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# 4) now truncate to exactly the number the caller wanted\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "# === Step 4: Prepare your financial totals ===\n",
    "finances = {\n",
    "    \"Revenue\": 102_709_000,\n",
    "    \"COGS\": -80_578_387,\n",
    "    \"FixedCost\": -17_916_252,\n",
    "    \"EBIT\": 4_214_272\n",
    "}\n",
    "rows_cfg = {\"Revenue\": 100, \"COGS\": 100, \"FixedCost\": 50, \"EBIT\": 50}\n",
    "\n",
    "# === Step 5: Run one category at a time ===\n",
    "revenue_accounts = df_accounts[df_accounts[\"AccountKey\"].between(4001, 4009)]\n",
    "revenue_df = generate_category_lines(\n",
    "    company_name,\n",
    "    \"Revenue\",\n",
    "    finances[\"Revenue\"],\n",
    "    rows_cfg[\"Revenue\"],\n",
    "    revenue_accounts,\n",
    "    bu_df,\n",
    "    parties_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4729f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac683471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_number</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>company</th>\n",
       "      <th>BU_ID</th>\n",
       "      <th>Party_ID</th>\n",
       "      <th>AccountKey</th>\n",
       "      <th>AccountName</th>\n",
       "      <th>item_name</th>\n",
       "      <th>amount_DKK</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOC000001</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>BU014</td>\n",
       "      <td>CUST003</td>\n",
       "      <td>4001</td>\n",
       "      <td>LEGO Retail Gross Sales</td>\n",
       "      <td>Retail POS sales - North America - Amazon mark...</td>\n",
       "      <td>948703.38</td>\n",
       "      <td>Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOC000002</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>BU015</td>\n",
       "      <td>CUST001</td>\n",
       "      <td>4001</td>\n",
       "      <td>LEGO Retail Gross Sales</td>\n",
       "      <td>Retail POS sales - DACH &amp; Nordics - Walmart ma...</td>\n",
       "      <td>948703.38</td>\n",
       "      <td>Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DOC000003</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>BU014</td>\n",
       "      <td>CUST002</td>\n",
       "      <td>4001</td>\n",
       "      <td>LEGO Retail Gross Sales</td>\n",
       "      <td>Retail POS sales - North America - Target onli...</td>\n",
       "      <td>948703.38</td>\n",
       "      <td>Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOC000004</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>BU015</td>\n",
       "      <td>CUST005</td>\n",
       "      <td>4001</td>\n",
       "      <td>LEGO Retail Gross Sales</td>\n",
       "      <td>Retail POS sales - DACH &amp; Nordics - Smyths Toy...</td>\n",
       "      <td>948703.38</td>\n",
       "      <td>Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOC000005</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>BU014</td>\n",
       "      <td>CUST012</td>\n",
       "      <td>4001</td>\n",
       "      <td>LEGO Retail Gross Sales</td>\n",
       "      <td>Retail POS sales - North America - MediaMarkt ...</td>\n",
       "      <td>948703.38</td>\n",
       "      <td>Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>DOC000113</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>BU013</td>\n",
       "      <td>CUST005</td>\n",
       "      <td>4004</td>\n",
       "      <td>Trade Channel Gross Sales</td>\n",
       "      <td>Order - Smyths - Half-term</td>\n",
       "      <td>1304467.15</td>\n",
       "      <td>Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DOC000114</td>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>BU013</td>\n",
       "      <td>CUST006</td>\n",
       "      <td>4004</td>\n",
       "      <td>Trade Channel Gross Sales</td>\n",
       "      <td>Window - The Entertainer - Summer line-up</td>\n",
       "      <td>1304467.15</td>\n",
       "      <td>Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>DOC000115</td>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>BU013</td>\n",
       "      <td>CUST008</td>\n",
       "      <td>4004</td>\n",
       "      <td>Trade Channel Gross Sales</td>\n",
       "      <td>Argos - Catalogue refresh</td>\n",
       "      <td>1304467.15</td>\n",
       "      <td>Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DOC000116</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>BU013</td>\n",
       "      <td>CUST009</td>\n",
       "      <td>4004</td>\n",
       "      <td>Trade Channel Gross Sales</td>\n",
       "      <td>Tesco - Toy aisle expansion</td>\n",
       "      <td>1304467.15</td>\n",
       "      <td>Revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>DOC000117</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>BU010</td>\n",
       "      <td>CUST010</td>\n",
       "      <td>4004</td>\n",
       "      <td>Trade Channel Gross Sales</td>\n",
       "      <td>Carrefour - Summer toys</td>\n",
       "      <td>1304467.30</td>\n",
       "      <td>Revenue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_number posting_date company  BU_ID Party_ID  AccountKey  \\\n",
       "0        DOC000001   2024-01-03    LEGO  BU014  CUST003        4001   \n",
       "1        DOC000002   2024-01-04    LEGO  BU015  CUST001        4001   \n",
       "2        DOC000003   2024-01-05    LEGO  BU014  CUST002        4001   \n",
       "3        DOC000004   2024-01-06    LEGO  BU015  CUST005        4001   \n",
       "4        DOC000005   2024-01-07    LEGO  BU014  CUST012        4001   \n",
       "..             ...          ...     ...    ...      ...         ...   \n",
       "95       DOC000113   2024-05-16    LEGO  BU013  CUST005        4004   \n",
       "96       DOC000114   2024-05-17    LEGO  BU013  CUST006        4004   \n",
       "97       DOC000115   2024-05-18    LEGO  BU013  CUST008        4004   \n",
       "98       DOC000116   2024-05-19    LEGO  BU013  CUST009        4004   \n",
       "99       DOC000117   2024-05-20    LEGO  BU010  CUST010        4004   \n",
       "\n",
       "                  AccountName  \\\n",
       "0     LEGO Retail Gross Sales   \n",
       "1     LEGO Retail Gross Sales   \n",
       "2     LEGO Retail Gross Sales   \n",
       "3     LEGO Retail Gross Sales   \n",
       "4     LEGO Retail Gross Sales   \n",
       "..                        ...   \n",
       "95  Trade Channel Gross Sales   \n",
       "96  Trade Channel Gross Sales   \n",
       "97  Trade Channel Gross Sales   \n",
       "98  Trade Channel Gross Sales   \n",
       "99  Trade Channel Gross Sales   \n",
       "\n",
       "                                            item_name  amount_DKK category  \n",
       "0   Retail POS sales - North America - Amazon mark...   948703.38  Revenue  \n",
       "1   Retail POS sales - DACH & Nordics - Walmart ma...   948703.38  Revenue  \n",
       "2   Retail POS sales - North America - Target onli...   948703.38  Revenue  \n",
       "3   Retail POS sales - DACH & Nordics - Smyths Toy...   948703.38  Revenue  \n",
       "4   Retail POS sales - North America - MediaMarkt ...   948703.38  Revenue  \n",
       "..                                                ...         ...      ...  \n",
       "95                         Order - Smyths - Half-term  1304467.15  Revenue  \n",
       "96          Window - The Entertainer - Summer line-up  1304467.15  Revenue  \n",
       "97                          Argos - Catalogue refresh  1304467.15  Revenue  \n",
       "98                        Tesco - Toy aisle expansion  1304467.15  Revenue  \n",
       "99                            Carrefour - Summer toys  1304467.30  Revenue  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revenue_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3861c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_LINES = \"\"\"\n",
    "You are a financial data generator simulating {company_name}'s general ledger for the category \"{category_name}\".\n",
    "\n",
    "The total amount across all rows must approximately equal {financial_total} DKK.\n",
    "\n",
    "Generate {over_request_count} detailed line items that could realistically appear in the general ledger for this category.\n",
    "\n",
    "Use the following context tables to inspire your results:\n",
    "- Chart of accounts (AccountKey;name):\n",
    "{accounts_subset_csv}\n",
    "\n",
    "- Business units (semicolon-separated CSV):\n",
    "{business_units_csv}\n",
    "\n",
    "- Relevant counterparties (semicolon-separated CSV):\n",
    "{parties_csv}\n",
    "\n",
    "Return a semicolon-separated table (no markdown, no commentary) with these columns:\n",
    "name;AccountKey;AccountName;BusinessUnit;PartyName;Quantity;UnitPrice;Amount;Description\n",
    "\n",
    "Rules:\n",
    "- \"name\" should be a realistic product, item, or service name (e.g., \"Lego Duplo Set\", \"Consulting Fee\", \"Electricity Invoice\").\n",
    "- \"AccountKey\" must be one from the accounts_subset_csv.\n",
    "- \"Amount\" should align with UnitPrice * Quantity, and the total should be close to {financial_total}.\n",
    "- Ensure diversity in items, parties, and business units.\n",
    "- Do NOT include headers or explanations outside the CSV table.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7ebd1bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only received 55 rows, expected 56\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_lines = \u001b[43mgenerate_category_lines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompany_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLEGO Group\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategory_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRevenue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinancial_total\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1_500_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrow_count\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccounts_subset_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_accounts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbu_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbu_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparties_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparties_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mgenerate_category_lines\u001b[39m\u001b[34m(company_name, category_name, financial_total, row_count, accounts_subset_df, bu_df, parties_df, model, temp, over_factor)\u001b[39m\n\u001b[32m     20\u001b[39m prompt_kwargs = {\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompany_name\u001b[39m\u001b[33m\"\u001b[39m: company_name,\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcategory_name\u001b[39m\u001b[33m\"\u001b[39m: category_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mparties_csv\u001b[39m\u001b[33m\"\u001b[39m: parties_df.to_csv(index=\u001b[38;5;28;01mFalse\u001b[39;00m, sep=\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     28\u001b[39m }\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# --- 2. Call LLM with overrequest logic ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m df_lines = \u001b[43mcall_llm_overrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPROMPT_LINES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mover_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mover_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# At this point:\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# - call_llm_overrequest() has already:\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m#   * asked for row_count * over_factor\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Ensure amount_DKK is numeric\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mamount_DKK\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df_lines.columns:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mcall_llm_overrequest\u001b[39m\u001b[34m(prompt_template, prompt_kwargs, count, model, temp, over_factor)\u001b[39m\n\u001b[32m     37\u001b[39m df_full = prompt_utils.parse_and_truncate_csv(\n\u001b[32m     38\u001b[39m     raw_text,\n\u001b[32m     39\u001b[39m     over_request_count\n\u001b[32m     40\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# 3) sanity check: did we at least get `count` usable rows?\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_full\u001b[49m\u001b[43m)\u001b[49m < count:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     45\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLLM underfilled: needed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows but only got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_full)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m usable rows \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     46\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mafter requesting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mover_request_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     47\u001b[39m     )\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# 4) now truncate to exactly the number the caller wanted\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "df_lines = generate_category_lines(\n",
    "    company_name=\"LEGO Group\",\n",
    "    category_name=\"Revenue\",\n",
    "    financial_total=1_500_000,\n",
    "    row_count=40,\n",
    "    accounts_subset_df=df_accounts,\n",
    "    bu_df=bu_df,\n",
    "    parties_df=parties_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d10c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DemoDataVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
